{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Aplicacion_Panoramicas_Automaticas.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {}
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/IA2021UR/trabajo-ia-en-la-comunidad-de-la-rioja-equipo-3/blob/main/Aplicacion_Panoramicas_Automaticas.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5RExD-nnBygl"
      },
      "source": [
        "import cv2\n",
        "from google.colab.patches import cv2_imshow"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HmTmvurr7yvm"
      },
      "source": [
        "def draw_matches(rotada1, keypoints1, rotada2, keypoints2, matches):\n",
        "    r, c = rotada1.shape[:2]\n",
        "    r1, c1 = rotada2.shape[:2]\n",
        "\n",
        "    # Create a blank image with the size of the first image + second image\n",
        "    output_img = np.zeros((max([r, r1]), c+c1, 3), dtype='uint8')\n",
        "    output_img[:r, :c, :] = np.dstack([rotada1, rotada1, rotada1])\n",
        "    output_img[:r1, c:c+c1, :] = np.dstack([rotada2, rotada2, rotada2])\n",
        "\n",
        "    # Go over all of the matching points and extract them\n",
        "    for match in matches:\n",
        "        img1_idx = match.queryIdx\n",
        "        img2_idx = match.trainIdx\n",
        "        (x1, y1) = keypoints1[img1_idx].pt\n",
        "        (x2, y2) = keypoints2[img2_idx].pt\n",
        "\n",
        "        # Draw circles on the keypoints\n",
        "        cv2.circle(output_img, (int(x1),int(y1)), 4, (0, 255, 255), 1)\n",
        "        cv2.circle(output_img, (int(x2)+c,int(y2)), 4, (0, 255, 255), 1)\n",
        "\n",
        "        # Connect the same keypoints\n",
        "        cv2.line(output_img, (int(x1),int(y1)), (int(x2)+c,int(y2)), (0, 255, 255), 1)\n",
        "    \n",
        "    return output_img"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x7Pl_CoA7udC"
      },
      "source": [
        "def warpImages(img1, img2, H):\n",
        "\n",
        "    rows1, cols1 = img1.shape[:2]\n",
        "    rows2, cols2 = img2.shape[:2]\n",
        "\n",
        "    list_of_points_1 = np.float32([[0,0], [0, rows1], [cols1, rows1], [cols1, 0]]).reshape(-1, 1, 2)\n",
        "    temp_points = np.float32([[0, 0], [0, rows2], [cols2, rows2], [cols2, 0]]).reshape(-1, 1, 2)\n",
        "\n",
        "    # When we have established a homography we need to warp perspective\n",
        "    # Change field of view\n",
        "    list_of_points_2 = cv2.perspectiveTransform(temp_points, H)\n",
        "\n",
        "    list_of_points = np.concatenate((list_of_points_1, list_of_points_2), axis=0)\n",
        "\n",
        "    [x_min, y_min] = np.int32(list_of_points.min(axis=0).ravel() - 0.5)\n",
        "    [x_max, y_max] = np.int32(list_of_points.max(axis=0).ravel() + 0.5)\n",
        "  \n",
        "    translation_dist = [-x_min, -y_min]\n",
        "  \n",
        "    H_translation = np.array([[1, 0, translation_dist[0]], [0, 1, translation_dist[1]], [0, 0, 1]])\n",
        "\n",
        "    output_img = cv2.warpPerspective(img2, H_translation.dot(H), (x_max-x_min, y_max-y_min))\n",
        "    output_img[translation_dist[1]:rows1+translation_dist[1], translation_dist[0]:cols1+translation_dist[0]] = img1\n",
        "\n",
        "    return output_img"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JFbCti7N6_2o"
      },
      "source": [
        "def stitch(img1, img2):\n",
        "    img1_gray = cv2.cvtColor(img1, cv2.COLOR_BGR2GRAY)\n",
        "    img2_gray = cv2.cvtColor(img2, cv2.COLOR_BGR2GRAY)\n",
        "    # Create our ORB detector and detect keypoints and descriptors\n",
        "    orb = cv2.ORB_create(nfeatures=2000)\n",
        "\n",
        "    # Find the key points and descriptors with ORB\n",
        "    keypoints1, descriptors1 = orb.detectAndCompute(img1, None)\n",
        "    keypoints2, descriptors2 = orb.detectAndCompute(img2, None)\n",
        "    img1KeyPoints=cv2.drawKeypoints(img1, keypoints1, None, (255, 0, 255))\n",
        "    img2KeyPoints=cv2.drawKeypoints(img2, keypoints2, None, (255, 0, 255))\n",
        "    # Create a BFMatcher object.\n",
        "    # It will find all of the matching keypoints on two images\n",
        "    bf = cv2.BFMatcher_create(cv2.NORM_HAMMING)\n",
        "\n",
        "    # Find matching points\n",
        "    matches = bf.knnMatch(descriptors1, descriptors2, k=2)\n",
        "    all_matches = []\n",
        "    for m, n in matches:\n",
        "        all_matches.append(m)\n",
        "\n",
        "    img3 = draw_matches(img1_gray, keypoints1, img2_gray, keypoints2, all_matches[:30])\n",
        "    # Finding the best matches\n",
        "    good = []\n",
        "    for m, n in matches:\n",
        "        if m.distance < 0.6 * n.distance:\n",
        "            good.append(m)\n",
        "    mostrarImagen(cv2.drawKeypoints(img1, [keypoints1[m.queryIdx] for m in good], None, (255, 0, 255)))\n",
        "    mostrarImagen(cv2.drawKeypoints(img2, [keypoints2[m.trainIdx] for m in good], None, (255, 0, 255)))\n",
        "    MIN_MATCH_COUNT = 10\n",
        "\n",
        "    if len(good) > MIN_MATCH_COUNT:\n",
        "        # Convert keypoints to an argument for findHomography\n",
        "        src_pts = np.float32([ keypoints1[m.queryIdx].pt for m in good]).reshape(-1, 1, 2)\n",
        "        dst_pts = np.float32([ keypoints2[m.trainIdx].pt for m in good]).reshape(-1, 1, 2)\n",
        "\n",
        "        # Establish a homography\n",
        "        M, _ = cv2.findHomography(src_pts, dst_pts, cv2.RANSAC, 5.0)\n",
        "        \n",
        "        result = warpImages(img2, img1, M)\n",
        "\n",
        "        cv2_imshow(result)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nuzkV5FjD-05",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 751,
          "referenced_widgets": [
            "37bd94420a794219a1dc96bf7f3b509e"
          ]
        },
        "outputId": "7108bd98-b7c4-4f92-c777-8bb367aaad83"
      },
      "source": [
        "#@title Selecciona un fichero .ZIP llamado fotos con dos imágenes dentro de una carpeta llamada fotos (las imágenes deben estar en formato JPG y llamarse 1 -la izquierda- y 2 -la derecha-)\n",
        "\n",
        "!pip install fastai --upgrade\n",
        "\n",
        "###\n",
        "\n",
        "from fastai.vision.all import *\n",
        "import os\n",
        "import zipfile\n",
        "from google.colab import files\n",
        "from sklearn.model_selection import train_test_split\n",
        "import shutil\n",
        "from fastai.vision.all import *\n",
        "from fastai.vision.widgets import *\n",
        "import PIL\n",
        "\n",
        "###\n",
        "\n",
        "btn_upload=widgets.FileUpload()\n",
        "out_pl=widgets.Output()\n",
        "lbl_pred=widgets.Label()\n",
        "\n",
        "###\n",
        "\n",
        "def on_data_change(change):\n",
        "  lbl_pred.value =''\n",
        "\n",
        "  out_pl.clear_output()\n",
        "  \n",
        "  fotos = btn_upload.data[-1]\n",
        "  !unzip fotos\n",
        "  img1 = cv2.imread(\"fotos/1.jpg\")\n",
        "  img2 = cv2.imread(\"fotos/2.jpg\")\n",
        "\n",
        "  lbl_pred.value=f'Resultado:'\n",
        "  stitch(img1, img2)\n",
        "\n",
        "###\n",
        "\n",
        "\n",
        "btn_upload.observe(on_data_change, names=['data'])\n",
        "display(VBox([widgets.Label('Selecciona un fichero .ZIP llamado fotos con dos imágenes dentro de una carpeta llamada fotos (las imágenes deben estar en formato JPG y llamarse 1 -la izquierda- y 2 -la derecha-).'),btn_upload, out_pl, lbl_pred]))"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already up-to-date: fastai in /usr/local/lib/python3.7/dist-packages (2.3.1)\n",
            "Requirement already satisfied, skipping upgrade: packaging in /usr/local/lib/python3.7/dist-packages (from fastai) (20.9)\n",
            "Requirement already satisfied, skipping upgrade: scipy in /usr/local/lib/python3.7/dist-packages (from fastai) (1.4.1)\n",
            "Requirement already satisfied, skipping upgrade: matplotlib in /usr/local/lib/python3.7/dist-packages (from fastai) (3.2.2)\n",
            "Requirement already satisfied, skipping upgrade: pandas in /usr/local/lib/python3.7/dist-packages (from fastai) (1.1.5)\n",
            "Requirement already satisfied, skipping upgrade: pyyaml in /usr/local/lib/python3.7/dist-packages (from fastai) (3.13)\n",
            "Requirement already satisfied, skipping upgrade: fastcore<1.4,>=1.3.8 in /usr/local/lib/python3.7/dist-packages (from fastai) (1.3.20)\n",
            "Requirement already satisfied, skipping upgrade: torch<1.9,>=1.7.0 in /usr/local/lib/python3.7/dist-packages (from fastai) (1.8.1+cu101)\n",
            "Requirement already satisfied, skipping upgrade: spacy<4 in /usr/local/lib/python3.7/dist-packages (from fastai) (2.2.4)\n",
            "Requirement already satisfied, skipping upgrade: fastprogress>=0.2.4 in /usr/local/lib/python3.7/dist-packages (from fastai) (1.0.0)\n",
            "Requirement already satisfied, skipping upgrade: pillow>6.0.0 in /usr/local/lib/python3.7/dist-packages (from fastai) (7.1.2)\n",
            "Requirement already satisfied, skipping upgrade: torchvision>=0.8.2 in /usr/local/lib/python3.7/dist-packages (from fastai) (0.9.1+cu101)\n",
            "Requirement already satisfied, skipping upgrade: requests in /usr/local/lib/python3.7/dist-packages (from fastai) (2.23.0)\n",
            "Requirement already satisfied, skipping upgrade: scikit-learn in /usr/local/lib/python3.7/dist-packages (from fastai) (0.22.2.post1)\n",
            "Requirement already satisfied, skipping upgrade: pip in /usr/local/lib/python3.7/dist-packages (from fastai) (19.3.1)\n",
            "Requirement already satisfied, skipping upgrade: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->fastai) (2.4.7)\n",
            "Requirement already satisfied, skipping upgrade: numpy>=1.13.3 in /usr/local/lib/python3.7/dist-packages (from scipy->fastai) (1.19.5)\n",
            "Requirement already satisfied, skipping upgrade: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->fastai) (0.10.0)\n",
            "Requirement already satisfied, skipping upgrade: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->fastai) (1.3.1)\n",
            "Requirement already satisfied, skipping upgrade: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->fastai) (2.8.1)\n",
            "Requirement already satisfied, skipping upgrade: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas->fastai) (2018.9)\n",
            "Requirement already satisfied, skipping upgrade: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch<1.9,>=1.7.0->fastai) (3.7.4.3)\n",
            "Requirement already satisfied, skipping upgrade: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy<4->fastai) (2.0.5)\n",
            "Requirement already satisfied, skipping upgrade: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy<4->fastai) (0.8.2)\n",
            "Requirement already satisfied, skipping upgrade: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.7/dist-packages (from spacy<4->fastai) (4.41.1)\n",
            "Requirement already satisfied, skipping upgrade: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy<4->fastai) (1.0.5)\n",
            "Requirement already satisfied, skipping upgrade: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.7/dist-packages (from spacy<4->fastai) (1.1.3)\n",
            "Requirement already satisfied, skipping upgrade: setuptools in /usr/local/lib/python3.7/dist-packages (from spacy<4->fastai) (56.1.0)\n",
            "Requirement already satisfied, skipping upgrade: thinc==7.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy<4->fastai) (7.4.0)\n",
            "Requirement already satisfied, skipping upgrade: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.7/dist-packages (from spacy<4->fastai) (1.0.0)\n",
            "Requirement already satisfied, skipping upgrade: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy<4->fastai) (1.0.5)\n",
            "Requirement already satisfied, skipping upgrade: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy<4->fastai) (0.4.1)\n",
            "Requirement already satisfied, skipping upgrade: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy<4->fastai) (3.0.5)\n",
            "Requirement already satisfied, skipping upgrade: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->fastai) (2.10)\n",
            "Requirement already satisfied, skipping upgrade: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->fastai) (2020.12.5)\n",
            "Requirement already satisfied, skipping upgrade: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->fastai) (1.24.3)\n",
            "Requirement already satisfied, skipping upgrade: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->fastai) (3.0.4)\n",
            "Requirement already satisfied, skipping upgrade: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->fastai) (1.0.1)\n",
            "Requirement already satisfied, skipping upgrade: six in /usr/local/lib/python3.7/dist-packages (from cycler>=0.10->matplotlib->fastai) (1.15.0)\n",
            "Requirement already satisfied, skipping upgrade: importlib-metadata>=0.20; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy<4->fastai) (4.0.1)\n",
            "Requirement already satisfied, skipping upgrade: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy<4->fastai) (3.4.1)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "37bd94420a794219a1dc96bf7f3b509e",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "VBox(children=(Label(value='Selecciona un fichero .ZIP llamado fotos con dos imágenes dentro de una carpeta ll…"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    }
  ]
}