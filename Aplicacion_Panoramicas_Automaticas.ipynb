{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Aplicacion_Panoramicas_Automaticas.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPrsw7HPym76nZGHUabXRZa",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/IA2021UR/trabajo-ia-en-la-comunidad-de-la-rioja-equipo-3/blob/main/Aplicacion_Panoramicas_Automaticas.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5RExD-nnBygl"
      },
      "source": [
        "import cv2\n",
        "from google.colab.patches import cv2_imshow"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HmTmvurr7yvm"
      },
      "source": [
        "def draw_matches(rotada1, keypoints1, rotada2, keypoints2, matches):\n",
        "    r, c = rotada1.shape[:2]\n",
        "    r1, c1 = rotada2.shape[:2]\n",
        "\n",
        "    # Create a blank image with the size of the first image + second image\n",
        "    output_img = np.zeros((max([r, r1]), c+c1, 3), dtype='uint8')\n",
        "    output_img[:r, :c, :] = np.dstack([rotada1, rotada1, rotada1])\n",
        "    output_img[:r1, c:c+c1, :] = np.dstack([rotada2, rotada2, rotada2])\n",
        "\n",
        "    # Go over all of the matching points and extract them\n",
        "    for match in matches:\n",
        "        img1_idx = match.queryIdx\n",
        "        img2_idx = match.trainIdx\n",
        "        (x1, y1) = keypoints1[img1_idx].pt\n",
        "        (x2, y2) = keypoints2[img2_idx].pt\n",
        "\n",
        "        # Draw circles on the keypoints\n",
        "        cv2.circle(output_img, (int(x1),int(y1)), 4, (0, 255, 255), 1)\n",
        "        cv2.circle(output_img, (int(x2)+c,int(y2)), 4, (0, 255, 255), 1)\n",
        "\n",
        "        # Connect the same keypoints\n",
        "        cv2.line(output_img, (int(x1),int(y1)), (int(x2)+c,int(y2)), (0, 255, 255), 1)\n",
        "    \n",
        "    return output_img"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x7Pl_CoA7udC"
      },
      "source": [
        "def warpImages(img1, img2, H):\n",
        "\n",
        "    rows1, cols1 = img1.shape[:2]\n",
        "    rows2, cols2 = img2.shape[:2]\n",
        "\n",
        "    list_of_points_1 = np.float32([[0,0], [0, rows1], [cols1, rows1], [cols1, 0]]).reshape(-1, 1, 2)\n",
        "    temp_points = np.float32([[0, 0], [0, rows2], [cols2, rows2], [cols2, 0]]).reshape(-1, 1, 2)\n",
        "\n",
        "    # When we have established a homography we need to warp perspective\n",
        "    # Change field of view\n",
        "    list_of_points_2 = cv2.perspectiveTransform(temp_points, H)\n",
        "\n",
        "    list_of_points = np.concatenate((list_of_points_1, list_of_points_2), axis=0)\n",
        "\n",
        "    [x_min, y_min] = np.int32(list_of_points.min(axis=0).ravel() - 0.5)\n",
        "    [x_max, y_max] = np.int32(list_of_points.max(axis=0).ravel() + 0.5)\n",
        "  \n",
        "    translation_dist = [-x_min, -y_min]\n",
        "  \n",
        "    H_translation = np.array([[1, 0, translation_dist[0]], [0, 1, translation_dist[1]], [0, 0, 1]])\n",
        "\n",
        "    output_img = cv2.warpPerspective(img2, H_translation.dot(H), (x_max-x_min, y_max-y_min))\n",
        "    output_img[translation_dist[1]:rows1+translation_dist[1], translation_dist[0]:cols1+translation_dist[0]] = img1\n",
        "\n",
        "    return output_img"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JFbCti7N6_2o"
      },
      "source": [
        "def stitch(img1, img2):\n",
        "    img1_gray = cv2.cvtColor(img1, cv2.COLOR_BGR2GRAY)\n",
        "    img2_gray = cv2.cvtColor(img2, cv2.COLOR_BGR2GRAY)\n",
        "    # Create our ORB detector and detect keypoints and descriptors\n",
        "    orb = cv2.ORB_create(nfeatures=2000)\n",
        "\n",
        "    # Find the key points and descriptors with ORB\n",
        "    keypoints1, descriptors1 = orb.detectAndCompute(img1, None)\n",
        "    keypoints2, descriptors2 = orb.detectAndCompute(img2, None)\n",
        "    img1KeyPoints=cv2.drawKeypoints(img1, keypoints1, None, (255, 0, 255))\n",
        "    img2KeyPoints=cv2.drawKeypoints(img2, keypoints2, None, (255, 0, 255))\n",
        "    # Create a BFMatcher object.\n",
        "    # It will find all of the matching keypoints on two images\n",
        "    bf = cv2.BFMatcher_create(cv2.NORM_HAMMING)\n",
        "\n",
        "    # Find matching points\n",
        "    matches = bf.knnMatch(descriptors1, descriptors2, k=2)\n",
        "    all_matches = []\n",
        "    for m, n in matches:\n",
        "        all_matches.append(m)\n",
        "\n",
        "    img3 = draw_matches(img1_gray, keypoints1, img2_gray, keypoints2, all_matches[:30])\n",
        "    # Finding the best matches\n",
        "    good = []\n",
        "    for m, n in matches:\n",
        "        if m.distance < 0.6 * n.distance:\n",
        "            good.append(m)\n",
        "    mostrarImagen(cv2.drawKeypoints(img1, [keypoints1[m.queryIdx] for m in good], None, (255, 0, 255)))\n",
        "    mostrarImagen(cv2.drawKeypoints(img2, [keypoints2[m.trainIdx] for m in good], None, (255, 0, 255)))\n",
        "    MIN_MATCH_COUNT = 10\n",
        "\n",
        "    if len(good) > MIN_MATCH_COUNT:\n",
        "        # Convert keypoints to an argument for findHomography\n",
        "        src_pts = np.float32([ keypoints1[m.queryIdx].pt for m in good]).reshape(-1, 1, 2)\n",
        "        dst_pts = np.float32([ keypoints2[m.trainIdx].pt for m in good]).reshape(-1, 1, 2)\n",
        "\n",
        "        # Establish a homography\n",
        "        M, _ = cv2.findHomography(src_pts, dst_pts, cv2.RANSAC, 5.0)\n",
        "        \n",
        "        result = warpImages(img2, img1, M)\n",
        "\n",
        "        cv2_imshow(result)"
      ],
      "execution_count": 4,
      "outputs": []
    }
  ]
}